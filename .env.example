# brAIniac Environment Configuration

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b-instruct-q4_K_M

# Alternative model option (uncomment to use):
# OLLAMA_MODEL=qwen2.5:7b-instruct-q4_K_M

# Rolling Memory Configuration
# Maximum number of messages to keep in context (default: 20)
# Lower values = less VRAM, less context; Higher values = more VRAM, more context
MAX_CONTEXT_MESSAGES=20

# Logging Level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO
